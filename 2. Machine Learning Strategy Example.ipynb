{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 在交易策略中使用深度学习模型进行交易决策\n",
    "\n",
    "在这个 Notebook 中我们将尝试训练一个简单的自定义序贯（Sequential）模型，用于判断是否应该在技术指标出现交易信号的时候进行交易。通常来讲，技术指标是基于数学公式所计算出的指标值。技术指标会随行情变化而变化。技术指标可以更直接地反映股市所处的状态，为交易提供指导。比如说，我们在之前的 BackTrader 策略示例中就以收盘价上穿均线作为开仓条件，收盘价下穿均线作为平仓条件。\n",
    "\n",
    "然而，通过指标发出的买卖信号是一个随机过程，不可能非常准确。很多技术指标容易产生钝化，或发出一些错误的买卖信号。在本示例中，我们将设定一些，并通过机器学习模型做进一步的预测和判断。您可以通过回测来观察这样做是否能够改善交易结果。\n",
    "\n",
    "完成这个实验需要 TensorFlow 框架，请选择 conda_amazonei_tensorflow2_p36 环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始之前，可以首先升级环境自带的 TensorFlow 和 Keras 最新版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow keras\n",
    "!pip show tensorflow keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来安装实验需要的一些依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install backtrader\n",
    "!pip install matplotlib==3.1.3\n",
    "!pip install talib-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后安装火币 API 并重启内核："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HuobiRDCenter/huobi_Python\n",
    "directory = '/home/ec2-user/SageMaker/sagemaker-huobi-workshop'\n",
    "!cd {directory}/huobi_Python && python3 setup.py -q install\n",
    "!pip show huobi-client\n",
    "import os\n",
    "\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "在这个部分我们将进行数据的准备工作、训练必要的模型并编写策略的回测脚本。\n",
    "\n",
    "首先，应当确保环境变量中有 SageMaker 实例的默认路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "directory = '/home/ec2-user/SageMaker/sagemaker-huobi-workshop'  # '/root/sagemaker-huobi-workshop' for SageMaker Studio\n",
    "if directory not in sys.path:\n",
    "    print(directory, 'added to sys.path')\n",
    "    sys.path.append(directory)\n",
    "    \n",
    "prefix = 'model_training'\n",
    "\n",
    "# 创建输入和输出路径\n",
    "import pathlib\n",
    "\n",
    "pathlib.Path(directory + '/' + prefix + '/input/data').mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(directory + '/' + prefix + '/output').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义超参\n",
    "\n",
    "在开始之前我们先定义一下这个算法中包含几个重要的参数：\n",
    "  - long_threshold：当模型预测止盈概率超过此数值时做多 (0 到 1 之间的小数)。\n",
    "  - short_threshold：当模型预测止损概率超过此数值时做空 (0 到 1 之间的小数)。如果设为大于等于 1，策略就不会做空。\n",
    "  - profit_target：当交易盈利超过此比例时止盈（0 到 1 之间的小数）。\n",
    "  - stop_target：当交易损失超过此比例时止损（0 到 1 之间的小数）。\n",
    "  - look_back：每次预测使用过去多少个交易日（整数）的历史数据。（look_back = repeat_count * repeat_step）\n",
    "  - forward_window：每次预测向前推导多少个交易日（整数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认参数\n",
    "params = { \n",
    "    \"long_threshold\" : 0.5,\n",
    "    \"short_threshold\" : 1,\n",
    "    \"profit_target\" : 0.02,\n",
    "    \"stop_target\" : 0.01,\n",
    "    \"repeat_count\": 20,\n",
    "    \"repeat_step\": 1,\n",
    "    \"forward_window\": 10\n",
    "}\n",
    "\n",
    "long_threshold = params['long_threshold']\n",
    "short_threshold = params['short_threshold']\n",
    "profit_target = params['profit_target']\n",
    "stop_target = params['stop_target']\n",
    "\n",
    "repeat_count = params['repeat_count']\n",
    "repeat_step = params['repeat_step']\n",
    "look_back = repeat_count * repeat_step\n",
    "forward_window = params['forward_window']\n",
    "\n",
    "# 将参数以 json 格式保存至指定目录\n",
    "import json\n",
    "with open('{}/hyperparameters.json'.format(directory), 'w') as fp:\n",
    "    json.dump(params, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "在这个演示中，我们将多获取自2010年至今的数据用于模型训练和预测。首先我们 import 必要的依赖包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import talib as ta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练数据\n",
    "\n",
    "以下的代码将通过火币 API 调取必要的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huobi.client.market import MarketClient\n",
    "from huobi.constant import *\n",
    "from huobi.utils import *\n",
    "\n",
    "market_client = MarketClient(init_log=True)\n",
    "interval = CandlestickInterval.DAY1\n",
    "symbol = \"btcusdt\"\n",
    "\n",
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        list_obj = market_client.get_candlestick(symbol, interval, 1300)\n",
    "        # LogInfo.output(\"---- {interval} candlestick for {symbol} ----\".format(interval=interval, symbol=symbol))\n",
    "        # LogInfo.output_list(list_obj)\n",
    "        flag = False\n",
    "        print('Data load success')\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将调取的火币原始数据转换为 Pandas DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tradedate', 'high', 'low', 'open', 'close', 'count', 'amount', 'volume']\n",
    "df = pd.DataFrame([[i.id, i.high, i.low, i.open, i.close, i.count, i.amount, i.vol] for i in list_obj], columns=columns)\n",
    "# convert id timestamp to datetime\n",
    "timezone = pytz.timezone('Asia/Shanghai')\n",
    "df['tradedate'] = df['tradedate'].apply(lambda x: datetime.datetime.fromtimestamp(x).astimezone(timezone).strftime('%Y-%m-%d'))\n",
    "df.set_index('tradedate', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "output_path = '{}/{}/input/data/data_raw.csv'.format(directory, prefix)\n",
    "print('Location:', output_path)\n",
    "df.to_csv(output_path)\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = df.index[-1]\n",
    "print('Sample range:', start_date, '-', end_date)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "\n",
    "以下是我们实现准备的 Sequential 模型训练程序。该模型训练过程将执行 100 个 epoch。随着 epoch 数量的增加，应该能看到 loss 的持续下降以及 accuracy 的提升："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import talib as ta\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "# Optional\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "config_path = '{}/'.format(directory)\n",
    "input_path = '{}/{}/input/data/data_train.csv'.format(directory, prefix)\n",
    "raw_path = '{}/{}/input/data/data_raw.csv'.format(directory, prefix)\n",
    "train_path = '{}/{}/input/data/data_train.csv'.format(directory, prefix)\n",
    "test_path = '{}/{}/input/data/data_test.csv'.format(directory, prefix)\n",
    "output_path = '{}/{}/output'.format(directory, prefix)\n",
    "model_path = '{}/model.h5'.format(directory)\n",
    "\n",
    "\n",
    "# Process and prepare the data\n",
    "def get_data(params):\n",
    "    \n",
    "    # get and save hyperparameters\n",
    "    long_threshold = float(params['long_threshold'])\n",
    "    short_threshold = float(params['short_threshold'])\n",
    "    profit_target = float(params['profit_target'])\n",
    "    stop_target = float(params['stop_target'])\n",
    "\n",
    "    repeat_count = int(params['repeat_count'])\n",
    "    repeat_step = int(params['repeat_step'])\n",
    "    look_back = repeat_count * repeat_step\n",
    "    forward_window = int(params['forward_window'])\n",
    "    \n",
    "    # read data from s3\n",
    "    df = pd.read_csv(raw_path, index_col=0)\n",
    "    closePrice = df[\"close\"]\n",
    "\n",
    "    # use talib to calculate SMA and ROC\n",
    "    ## set header for transformed data\n",
    "    header = [\"tradedate\", \"close\"]\n",
    "    for i in range(0, repeat_count):\n",
    "        header.append(\"sma\" + str((i+1) * repeat_step))\n",
    "    for i in range(0, repeat_count):\n",
    "        header.append(\"roc\" + str((i+1) * repeat_step))\n",
    "    header.append(\"long\")\n",
    "    header.append(\"short\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    ## SMA\n",
    "    inputs = {'close': np.array(closePrice)}\n",
    "    sma = []\n",
    "    for i in range(0, repeat_count):\n",
    "        sma.append(ta.SMA(np.array(closePrice), timeperiod=(i+1) * repeat_step + 1))\n",
    "    ## ROC - Rate of change : ((price/prevPrice)-1)*100\n",
    "    roc = []\n",
    "    for i in range(0, repeat_count):\n",
    "        roc.append(ta.ROC(np.array(closePrice), timeperiod=(i+1) * repeat_step + 1))\n",
    "\n",
    "    ## count long and short\n",
    "    long_count = 0\n",
    "    short_count = 0\n",
    "    n_count = 0\n",
    "    n = 0\n",
    "    for idx in df.index:\n",
    "        if n < len(df) - forward_window - 1:\n",
    "            idx_0 = idx\n",
    "            close_price = df.loc[idx, 'close']\n",
    "            temp = []\n",
    "            temp.append(idx)\n",
    "\n",
    "            temp2 = []\n",
    "            temp2.append(close_price)\n",
    "\n",
    "            # sma\n",
    "            for i in range(0, repeat_count):\n",
    "                if np.isnan(sma[i][n]):\n",
    "                    temp2.append(close_price)\n",
    "                else:\n",
    "                    temp2.append(sma[i][n])\n",
    "\n",
    "            min_value = min(temp2)\n",
    "            max_value = max(temp2)\n",
    "            for i in temp2:\n",
    "                if max_value == min_value:\n",
    "                    temp.append(0)\n",
    "                else:\n",
    "                    temp.append((i - min_value) / (max_value - min_value))\n",
    "\n",
    "            for i in range(0, repeat_count):\n",
    "                if np.isnan(roc[i][n]):\n",
    "                    temp.append(0)\n",
    "                else:\n",
    "                    temp.append(roc[i][n])\n",
    "\n",
    "            rClose = closePrice[(n+1):min(len(df)-1, n+1+forward_window)].values.tolist()\n",
    "            min_value = min(rClose)\n",
    "            max_value = max(rClose)\n",
    "\n",
    "            # long condition\n",
    "            if max_value >= close_price * (1+profit_target) and min_value >= close_price * (1-stop_target):\n",
    "                long_count += 1\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "\n",
    "            # short condition\n",
    "            if min_value <= close_price * (1-stop_target) and max_value <= close_price * (1+profit_target):\n",
    "                short_count += 1\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "\n",
    "            data.append(temp)\n",
    "            n += 1\n",
    "\n",
    "    print(\"long：%s, short：%s\" % (long_count,short_count))\n",
    "    df2 = pd.DataFrame(data, columns=header)\n",
    "    df2.set_index('tradedate', inplace=True)\n",
    "    print('Range:', df2.index[0], '-', df2.index[-1])\n",
    "    \n",
    "    # save data\n",
    "    df_train = df2.iloc[:800]\n",
    "    print('Training set:', df_train.index[0], '-', df_train.index[-1])\n",
    "    print('Location:', train_path)\n",
    "    df_train.to_csv(train_path)\n",
    "\n",
    "    df_test = df2.iloc[800:1000]\n",
    "    print('Testing set:', df_test.index[0], '-', df_test.index[-1])\n",
    "    print('Location:', test_path)\n",
    "    df_test.to_csv(test_path)\n",
    "    \n",
    "\n",
    "# Process and prepare the data\n",
    "def data_process(df, yLen, b):\n",
    "    \n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for idx, row in df.iterrows():\n",
    "        row1 = []\n",
    "        r = row[1:len(row)-yLen]\n",
    "        for a in r:\n",
    "            row1.append(a)\n",
    "        x = np.array(row1, dtype=float)\n",
    "        y = np.array(row[len(row)-yLen:], dtype=float)\n",
    "        b = len(x)\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "        \n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)\n",
    "    \n",
    "    return dataX, dataY, b\n",
    "\n",
    "\n",
    "def build_classifier(b, yLen):\n",
    "    \n",
    "    print(\"build_classifier:b=%s,yLen=%s\" % (b, yLen))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(b, input_dim=b, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(b/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(yLen, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_model(dataX, dataY, b, yLen):\n",
    "    \n",
    "    model = build_classifier(b, yLen)\n",
    "    model.fit(dataX, dataY, epochs=100, batch_size=1)\n",
    "    scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "    print(\"Training Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    try:\n",
    "        with open(\"{}/hyperparameters.json\".format(config_path)) as json_file:\n",
    "            params = json.load(json_file)\n",
    "        print('Parameter load success')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    get_data(params)\n",
    "    \n",
    "    print('Starting the training.')\n",
    "    \n",
    "    yLen = 2\n",
    "    b = 0\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(input_path)\n",
    "        dataX, dataY, b = data_process(df, yLen, b)\n",
    "        print('b:', b, 'yLen:', yLen)\n",
    "        model = generate_model(dataX, dataY, b, yLen)\n",
    "        model.save(model_path)\n",
    "        \n",
    "        print('Training is complete. Model saved.')\n",
    "        \n",
    "        df = pd.read_csv(test_path)\n",
    "        dataX, dataY, b = data_process(df, yLen, b)\n",
    "        print('b:', b, 'yLen:', yLen)\n",
    "        scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "        print(\"Test Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failure\n",
    "        # Reason in the DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs\n",
    "        print(\n",
    "            'Exception during training: ' + str(e) + '\\n' + trc,\n",
    "            file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到 SystemExit: 0 则表明模型训练成功。\n",
    "\n",
    "训练完成后的模型保存在 model/ 路径下，应该可以看到路径下有名为 model.h5 的模型文件生成。可以运行以下代码尝试在 TensorFlow 中加载模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = '{}/model.h5'.format(directory)\n",
    "print('Model path:', model_path)\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print('Model load success')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of neural network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回测\n",
    "\n",
    "接下来我们将定义运行回测任务所需的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回测数据\n",
    "\n",
    "在开始前我们先配置好回测所需的数据和参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回测数据\n",
    "df_backtest= df.iloc[1000:]\n",
    "print('Backtest set:', df_backtest.index[0], '-', df_backtest.index[-1])\n",
    "df_backtest.head()\n",
    "\n",
    "# 超参\n",
    "with open(\"{}/hyperparameters.json\".format(directory)) as json_file:\n",
    "    params = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 策略定义\n",
    "\n",
    "接下来的脚本包含了运行回测所需的策略代码。该策略将从示例的路径中加载之前训练好的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib as ta\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "class MyStrategy(bt.Strategy):\n",
    "    \n",
    "    params = (\n",
    "        ('model_path', ''), \n",
    "        ('long_threshold', 0.5), \n",
    "        ('short_threshold', 1), \n",
    "        ('profit_target', 0.02), \n",
    "        ('stop_target', 0.01), \n",
    "        ('repeat_count', 20), \n",
    "        ('repeat_step', 1), \n",
    "        ('printlog', True))\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyStrategy, self).__init__()\n",
    "\n",
    "        self.order = None\n",
    "        self.orderPlaced = False\n",
    "                                \n",
    "        self.model = load_model(self.params.model_path)\n",
    "        \n",
    "        # input / indicators\n",
    "        self.long_threshold = self.params.long_threshold\n",
    "        self.short_threshold = self.params.short_threshold\n",
    "        self.repeat_count = self.params.repeat_count\n",
    "        self.repeat_step = self.params.repeat_step\n",
    "        self.profit_target = self.params.profit_target\n",
    "        self.stop_target = self.params.stop_target\n",
    "    \n",
    "        self.sma=[]\n",
    "        self.roc=[]\n",
    "        for i in range(0, self.repeat_count):\n",
    "            self.sma.append(bt.talib.SMA(self.data, timeperiod=(i+1)*self.repeat_step + 1, plot=False))\n",
    "            self.roc.append(bt.talib.ROC(self.data, timeperiod=(i+1)*self.repeat_step + 1, plot=False))\n",
    "        \n",
    "    def next(self):\n",
    "        super(MyStrategy, self).next()\n",
    "        \n",
    "        idx_0 = self.datas[0].datetime.datetime(0)\n",
    "        close_price = self.datas[0].close\n",
    "        temp = []\n",
    "        \n",
    "        temp2 = []\n",
    "        temp2.append(close_price)\n",
    "\n",
    "        ## sma\n",
    "        for i in range(0, self.repeat_count):\n",
    "            if math.isnan(self.sma[i][0]):\n",
    "                temp2.append(close_price)\n",
    "            else:\n",
    "                temp2.append(self.sma[i][0])\n",
    "                \n",
    "        min_value = min(temp2)\n",
    "        max_value = max(temp2)\n",
    "        for i in temp2:\n",
    "            if max_value == min_value:\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append((i - min_value) / (max_value - min_value))\n",
    "\n",
    "        ## roc\n",
    "        for i in range(0, self.repeat_count):\n",
    "            if math.isnan(self.roc[i][0]):\n",
    "                temp.append(0)\n",
    "            else:\n",
    "                temp.append(self.roc[i][0])\n",
    "        \n",
    "        ## dataX\n",
    "        dataX = np.array([np.array(temp)])\n",
    "\n",
    "        ## dataY\n",
    "        dataY = self.model.predict(dataX)\n",
    "        \n",
    "        \n",
    "        ## 开仓条件\n",
    "        tLong = dataY[0][0]\n",
    "#         tShort = dataY[0][1]\n",
    "        if not self.position:\n",
    "            fLong = (tLong > self.long_threshold) \n",
    "#             fShort = (tShort > self.short_threshold)\n",
    "            if fLong:\n",
    "                self.size = int(self.broker.cash / self.datas[0].close[0])\n",
    "                self.order = self.buy(size=self.size)\n",
    "                self.limitPrice = close_price + self.profit_target * close_price\n",
    "                self.stopPrice = close_price - self.stop_target * close_price\n",
    "#             elif fShort:\n",
    "#                 self.order = self.sell(size=self.size)                \n",
    "#                 self.limitPrice = close_price - self.profit_target * close_price\n",
    "#                 self.stopPrice = close_price + self.stop_target * close_price\n",
    "\n",
    "        ## 平仓逻辑\n",
    "        if self.position:\n",
    "            if self.position.size > 0:\n",
    "                if close_price >= self.limitPrice or close_price <= self.stopPrice:\n",
    "                    self.order = self.sell(size=self.size)\n",
    "#             elif self.position.size < 0:\n",
    "#                 if close_price <= self.limitPrice or close_price >= self.stopPrice:\n",
    "#                     self.order = self.buy(size=self.size)\n",
    "                    \n",
    "    ## 日志记录\n",
    "    def log(self, txt, dt=None, doprint=False):\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print(f'{dt.isoformat()},{txt}')\n",
    "\n",
    "    # 记录交易执行情况（可选，默认不输出结果）\n",
    "    def notify_order(self, order):\n",
    "        # 如果 order 为 submitted/accepted，返回空\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            return\n",
    "        # 如果 order 为 buy/sell executed，报告价格结果\n",
    "        if order.status in [order.Completed]: \n",
    "            if order.isbuy():\n",
    "                self.log(f'买入：\\n价格：%.2f,\\\n",
    "                交易金额：-%.2f,\\\n",
    "                手续费：%.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:\n",
    "                self.log(f'卖出:\\n价格：%.2f,\\\n",
    "                交易金额：%.2f,\\\n",
    "                手续费：%.2f' % (order.executed.price, order.executed.price*self.size, order.executed.comm))\n",
    "            self.bar_executed = len(self) \n",
    "\n",
    "        # 如果指令取消/交易失败, 报告结果\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('交易失败')\n",
    "        self.order = None\n",
    "\n",
    "    # 记录交易收益情况（可省略，默认不输出结果）\n",
    "    def notify_trade(self,trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "        self.log(f'策略收益\\n毛收益 {trade.pnl:.2f}, 净收益 {trade.pnlcomm:.2f}')\n",
    "\n",
    "    # 回测结束后输出结果（可省略，默认输出结果）\n",
    "    def stop(self):\n",
    "        self.log('期末总资金 %.2f' %\n",
    "                 (self.broker.getvalue()), doprint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行回测任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "import datetime\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import backtrader as bt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建 Cerebro 对象\n",
    "    cerebro = bt.Cerebro()\n",
    "\n",
    "    # 创建 Data Feed\n",
    "    df_backtest.index = pd.to_datetime(df_backtest.index)\n",
    "    start = df_backtest.index[0]\n",
    "    end = df_backtest.index[-1]\n",
    "    print(start, '-', end)\n",
    "    data = bt.feeds.PandasData(dataname=df_backtest, fromdate=start, todate=end)\n",
    "    \n",
    "    # 将 Data Feed 添加至 Cerebro\n",
    "    cerebro.adddata(data)\n",
    "\n",
    "    # 添加策略 Cerebro\n",
    "    cerebro.addstrategy(MyStrategy, \n",
    "                        model_path=model_path,\n",
    "                        long_threshold=params[\"long_threshold\"], \n",
    "                        short_threshold=params[\"short_threshold\"], \n",
    "                        profit_target=params[\"profit_target\"], \n",
    "                        stop_target=params[\"stop_target\"],\n",
    "                        repeat_count=params[\"repeat_count\"], \n",
    "                        repeat_step=params[\"repeat_step\"])\n",
    "    \n",
    "    # 设置初始资金\n",
    "    cerebro.broker.setcash(100000.0)\n",
    "    # 设置手续费为万二\n",
    "    cerebro.broker.setcommission(commission=0.0002) \n",
    "\n",
    "    # 在开始时 print 初始账户价值\n",
    "    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
    "\n",
    "    # 运行回测流程\n",
    "    cerebro.run()\n",
    "\n",
    "    # 在结束时 print 最终账户价值\n",
    "    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# 画图并保存\n",
    "fig = cerebro.plot(iplot=False)[0][0]\n",
    "fig.set_size_inches(30, 18)\n",
    "fig.savefig('{}/plot.png'.format(directory), dpi=100)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
