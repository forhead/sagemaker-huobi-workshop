{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 SageMaker 进行超参优化\n",
    "\n",
    "要第二步的实验中，我们应当成功训练了一个机器学习模型进行交易，但交易的结果可能并不理想。因此在这个 NoteBook 中，我们将使用 SageMaker 的超参优化能力模型进行调优，以试图改善交易的结果。\n",
    "\n",
    "要完成这个实验，请选择 conda_python3 环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实验开始之前，首先应当先确保环境中安装有火币的 API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HuobiRDCenter/huobi_Python\n",
    "directory = '/home/ec2-user/SageMaker/sagemaker-huobi-workshop'  # '/root/sagemaker-huobi-workshop' for SageMaker Studio\n",
    "!cd {directory}/huobi_Python && python3 setup.py -q install\n",
    "!pip show huobi-client\n",
    "import os\n",
    "\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "在这个部分我们将配置变量并准备环境。\n",
    "\n",
    "首先，应当确保环境变量中有 SageMaker 实例的默认路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "directory = '/home/ec2-user/SageMaker/sagemaker-huobi-workshop'  # '/root/sagemaker-huobi-workshop' for SageMaker Studio\n",
    "if directory not in sys.path:\n",
    "    print(directory, 'added to sys.path')\n",
    "    sys.path.append(directory)\n",
    "    \n",
    "prefix = 'hyperparameter_optimization'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，配置一些 SageMaker 训练任务相关的变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "aws_default_region = session.boto_session.region_name\n",
    "aws_account_id = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = session.default_bucket()\n",
    "print('存储桶：', bucket)\n",
    "\n",
    "model_name = 'prediction'\n",
    "print('模型：', model_name)\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, model_name)\n",
    "print('输出路径：', output_location)\n",
    "\n",
    "image_name = 'huobi'\n",
    "image_tag = 'latest'\n",
    "image_uri = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(aws_account_id, aws_default_region, model_name, image_tag)\n",
    "print('镜像：', image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下，获取火币的原始行情数据，并存储到 S3 桶的指定目录中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huobi.client.market import MarketClient\n",
    "from huobi.constant import *\n",
    "from huobi.utils import *\n",
    "\n",
    "# get data from huobi\n",
    "market_client = MarketClient(init_log=True)\n",
    "interval = CandlestickInterval.DAY1\n",
    "symbol = \"btcusdt\"\n",
    "\n",
    "flag = True\n",
    "while flag:\n",
    "    try:\n",
    "        list_obj = market_client.get_candlestick(symbol, interval, 1300)\n",
    "        # LogInfo.output(\"---- {interval} candlestick for {symbol} ----\".format(interval=interval, symbol=symbol))\n",
    "        # LogInfo.output_list(list_obj)\n",
    "        flag = False\n",
    "        print('Data load success')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# transform huobi data to Pandas DataFrame\n",
    "columns = ['tradedate', 'high', 'low', 'open', 'close', 'count', 'amount', 'volume']\n",
    "df = pd.DataFrame([[i.id, i.high, i.low, i.open, i.close, i.count, i.amount, i.vol] for i in list_obj], columns=columns)\n",
    "timezone = pytz.timezone('Asia/Shanghai')\n",
    "df['tradedate'] = df['tradedate'].apply(lambda x: datetime.datetime.fromtimestamp(x).astimezone(timezone).strftime('%Y-%m-%d'))\n",
    "df.set_index('tradedate', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "start_date = df.index[0]\n",
    "end_date = df.index[-1]\n",
    "print('Sample range:', start_date, '-', end_date)\n",
    "\n",
    "# save data to s3\n",
    "s3.put_object(Body=df.to_csv(), Bucket=bucket, Key='{}/input/data_raw.csv'.format(model_name))\n",
    "raw_data_path = 's3://{}/{}/input/data_raw.csv'.format(bucket, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试自定义算法容器\n",
    "\n",
    "在这个演示中，我们将使用 SageMaker 的超参优化功能。这需要将算法打包至容器中在 SageMaker 上运行。在此之前，可以先在本地构建镜像，并且使用默认参数简单测试自定义算法容器是否可以正常运行。\n",
    "\n",
    "本实验中提供了一个示例 TensorFlow 自定义 Dockerfile。可以运行以下命令在本地环境进行 build："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo docker stop $(sudo docker ps -a -q)\n",
    "# !sudo docker rm $(sudo docker ps -a -q)\n",
    "# !sudo docker rmi $(sudo docker images)\n",
    "# !docker ps -a\n",
    "# !docker images\n",
    "!cd {directory} && sudo docker build {prefix} -t {image_name}:{image_tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "镜像创建成功后，我们可以在本地环境运行镜像，测试是否能够成功运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default parameters\n",
    "params = { \n",
    "    \"long_threshold\" : 0.5,\n",
    "    \"short_threshold\" : 1,\n",
    "    \"profit_target\" : 0.02,\n",
    "    \"stop_target\" : 0.01,\n",
    "    \"repeat_count\": 20,\n",
    "    \"repeat_step\": 1,\n",
    "    \"forward_window\": 10\n",
    "}\n",
    "\n",
    "base_job_name = model_name\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    'huobi:latest',\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='local',\n",
    "    output_path=output_location,\n",
    "    base_job_name=base_job_name, \n",
    "    hyperparameters=params,\n",
    ")\n",
    "\n",
    "estimator.fit(raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在确认容器能够成功运行后，我们需要将容器推送至 ECR 镜像仓库，以便在超参优化任务中使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ECR repository\n",
    "!aws ecr create-repository --repository-name {model_name} --region {aws_default_region} > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_image = !docker images -q {image_name}:{image_tag} 2> /dev/null\n",
    "if len(exist_image) > 0:\n",
    "    !docker tag {image_name}:{image_tag} {image_uri}\n",
    "!$(aws ecr get-login --region {aws_default_region} --no-include-email)\n",
    "print('Pushing image')\n",
    "!docker push {image_uri}\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参优化\n",
    "\n",
    "在开始之前，我们需要花一些时间来进行超参优化任务的配置。这些配置主要包括超参的定义和取值范围、目标参数的定义以及从日志中提取目标参数所需的正则表达式。这些配置信息通过 JSON 格式定义："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参优化任务名称\n",
    "tuning_job_name = model_name\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# 超参调优的参数配置\n",
    "hyperparameter_ranges = {\n",
    "    'long_threshold': ContinuousParameter(0.1, 0.9),\n",
    "    'short_threshold': ContinuousParameter(1.0, 1.1),\n",
    "    'profit_target': ContinuousParameter(0.01, 0.1),\n",
    "    'stop_target': ContinuousParameter(0.01, 0.1),\n",
    "    'repeat_count': IntegerParameter(10, 30),\n",
    "    'repeat_step': IntegerParameter(1, 2),\n",
    "    'forward_window': IntegerParameter(5, 30)\n",
    "}\n",
    "\n",
    "# 目标参数的配置\n",
    "metric_definitions = [\n",
    "    {\n",
    "        'Name': 'loss', \n",
    "        'Regex': 'loss: ([0-9\\\\.]+)%'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'accuracy', \n",
    "        'Regex': 'accuracy: ([0-9\\\\.]+)%'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'train:accuracy', \n",
    "        'Regex': 'Training Data accuracy: ([0-9\\\\.]+)%'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'test:accuracy', \n",
    "        'Regex': 'Test Data accuracy: ([0-9\\\\.]+)%'\n",
    "    }\n",
    "]\n",
    "objective_metric_name = \"test:accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们将在 SageMaker 中启动一个超参优化任务来寻找最优的参数组合。每一个超参优化任务会并行启动多个容器进行模型训练和测试，任务可能会持续至少数十分钟。我们可以尝试挑战超参优化中的一些参数来提升运行的效率，例如参数的取值范围、任务节点数量、训练任务总数等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.4xlarge',\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=session\n",
    ")\n",
    "\n",
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator, \n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    strategy='Bayesian',\n",
    "    objective_type='Maximize', \n",
    "    max_jobs=100,\n",
    "    max_parallel_jobs=10,\n",
    "    base_tuning_job_name=tuning_job_name,\n",
    "    early_stopping_type='Auto'\n",
    ")\n",
    "\n",
    "tuner.fit(raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在超参优化任务结束之后，我们可以通过以下代码查看优化的结果,并选取一个理想的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_analytics = tuner.analytics()\n",
    "tuning_result = tuner_analytics.dataframe().sort_values(['FinalObjectiveValue'], ascending=False)\n",
    "\n",
    "# select desired training result\n",
    "i = 0\n",
    "selected_training_job = tuning_result[\"TrainingJobName\"].iloc[i]\n",
    "\n",
    "params = { \n",
    "    \"long_threshold\" : float(tuning_result[\"long_threshold\"].iloc[i]),\n",
    "    \"short_threshold\" : float(tuning_result[\"short_threshold\"].iloc[i]),\n",
    "    \"profit_target\" : float(tuning_result[\"profit_target\"].iloc[i]),\n",
    "    \"stop_target\" : float(tuning_result[\"stop_target\"].iloc[i]),\n",
    "    \"repeat_count\": int(tuning_result[\"repeat_count\"].iloc[i]),\n",
    "    \"repeat_step\": int(tuning_result[\"repeat_step\"].iloc[i]),\n",
    "    \"forward_window\": int(tuning_result[\"forward_window\"].iloc[i]),\n",
    "}\n",
    "\n",
    "import json\n",
    "hyperparameter_path = '{}/hyperparameters.json'.format(directory)\n",
    "print('超参路径：', hyperparameter_path)\n",
    "with open(hyperparameter_path, 'w') as fp:\n",
    "    json.dump(params, fp)\n",
    "\n",
    "tuning_result.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完成后的模型由 SageMaker 自动打包并上传至 S3。我们只需找到最优的训练任务，并将其生产的 \"model.h5\" 的模型文件解压缩到实验目录下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import tarfile\n",
    "\n",
    "s3_output_path = '{}/output/{}/output/model.tar.gz'.format(model_name, selected_training_job)\n",
    "print('s3路径：', s3_output_path)\n",
    "\n",
    "bytestream = io.BytesIO(s3.get_object(Bucket=bucket, Key=s3_output_path)['Body'].read())\n",
    "compressed_file = tarfile.open(fileobj=bytestream)\n",
    "extract_path = '{}/'.format(directory)\n",
    "compressed_file.extractall(path=extract_path)\n",
    "model_path = extract_path + 'model.h5'\n",
    "print('模型路径：', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型和超参保存成功后，就可以第二个 Notebook 的“回测”步骤对模型再进行验证了。"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
